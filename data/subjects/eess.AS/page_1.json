[{"doi":"2511.04376v1","title":"MusRec: Zero-Shot Text-to-Music Editing via Rectified Flow and Diffusion Transformers","authors":["Ali Boudaghi","Hadi Zare"],"published":"2025-11-06","url":"http://arxiv.org/abs/2511.04376v1"},{"doi":"2511.03601v1","title":"Step-Audio-EditX Technical Report","authors":["Chao Yan","Boyong Wu","Peng Yang","Pengfei Tan","Guoqiang Hu","Yuxin Zhang","Xiangyu","Zhang","Fei Tian","Xuerui Yang","Xiangyu Zhang","Daxin Jiang","Gang Yu"],"published":"2025-11-05","url":"http://arxiv.org/abs/2511.03601v1"},{"doi":"2511.03361v1","title":"Open Source State-Of-the-Art Solution for Romanian Speech Recognition","authors":["Gabriel Pirlogeanu","Alexandru-Lucian Georgescu","Horia Cucu"],"published":"2025-11-05","url":"http://arxiv.org/abs/2511.03361v1"},{"doi":"2511.03423v1","title":"Seeing What You Say: Expressive Image Generation from Speech","authors":["Jiyoung Lee","Song Park","Sanghyuk Chun","Soo-Whan Chung"],"published":"2025-11-05","url":"http://arxiv.org/abs/2511.03423v1"},{"doi":"2511.03089v1","title":"A Computational Approach to Analyzing Disrupted Language in Schizophrenia: Integrating Surprisal and Coherence Measures","authors":["Gowtham Premananth","Carol Espy-Wilson"],"published":"2025-11-05","url":"http://arxiv.org/abs/2511.03089v1"},{"doi":"2511.03086v1","title":"Speech-Based Prioritization for Schizophrenia Intervention","authors":["Gowtham Premananth","Philip Resnik","Sonia Bansal","Deanna L. Kelly","Carol Espy-Wilson"],"published":"2025-11-05","url":"http://arxiv.org/abs/2511.03086v1"},{"doi":"2511.03084v1","title":"Quantifying Articulatory Coordination as a Biomarker for Schizophrenia","authors":["Gowtham Premananth","Carol Espy-Wilson"],"published":"2025-11-05","url":"http://arxiv.org/abs/2511.03084v1"},{"doi":"2511.02717v1","title":"An unscented Kalman filter method for real time input-parameter-state estimation","authors":["Marios Impraimakis","Andrew W. Smyth"],"published":"2025-11-04","url":"http://arxiv.org/abs/2511.02717v1"},{"doi":"2511.02252v1","title":"From the perspective of perceptual speech quality: The robustness of frequency bands to noise","authors":["Junyi Fan","Donald S. Williamson"],"published":"2025-11-04","url":"http://arxiv.org/abs/2511.02252v1"},{"doi":"2511.01261v1","title":"Speech-DRAME: A Framework for Human-Aligned Benchmarks in Speech Role-Play","authors":["Jiatong Shi","Jionghao Han","Yichen Lu","Santiago Pascual","Pengfei Wu","Chenye Cui","Shinji Watanabe","Chao Weng","Cong Zhou"],"published":"2025-11-03","url":"http://arxiv.org/abs/2511.01261v1"},{"doi":"2511.00850v1","title":"MULTI-Bench: A Multi-Turn Interactive Benchmark for Assessing Emotional Intelligence ability of Spoken Dialogue Models","authors":["Yayue Deng","Guoqiang Hu","Haiyang Sun","Xiangyu Zhang","Haoyang Zhang","Fei Tian","Xuerui Yang","Gang Yu","Eng Siong Chng"],"published":"2025-11-02","url":"http://arxiv.org/abs/2511.00850v1"},{"doi":"2511.04691v1","title":"A Penny for Your Thoughts: Decoding Speech from Inexpensive Brain Signals","authors":["Quentin Auster","Kateryna Shapovalenko","Chuang Ma","Demaio Sun"],"published":"2025-10-28","url":"http://arxiv.org/abs/2511.04691v1"},{"doi":"2511.01868v1","title":"Condition-Invariant fMRI Decoding of Speech Intelligibility with Deep State Space Model","authors":["Ching-Chih Sung","Shuntaro Suzuki","Francis Pingfan Chien","Komei Sugiura","Yu Tsao"],"published":"2025-10-21","url":"http://arxiv.org/abs/2511.01868v1"}]